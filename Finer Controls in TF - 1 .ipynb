{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In [1] to In [6] are ways of defining a graph "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classic import statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants:\n",
    "It is a type of node whose value doesn't change over time. It can be defined as "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "constant_node = tf.constant(3, tf.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Common Pitfall #1 :: Print a node directly to get its value.\n",
    "Just creating a node doesn't mean it is directly usable. Let's see what we get when we try to print it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print(constant_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### What went wrong\n",
    "This node is just a static node and is of no use unless we create a session connection to the graph and then run it through that session. We'll cover that in later part of this file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders:\n",
    "Placeholders are nodes that acts as means to accept inputs into the computational graph from the user. They can be defined as "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "placeholder_node = tf.placeholder(tf.float32, shape=[None, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like its constant counterpart, it is of no use unless we create a session connection to the graph and then run it through that session. Note that *None* here means any number of rows is acceptable as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder:0\", shape=(?, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(placeholder_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables:\n",
    "These are the nodes that contain the parametric values of any model. Remember that the parameters of a DL model are its weights and biases. Hence, we define our weights and biases (in fact any new unconventional parameter that you might want to test) nodes like the following "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight = tf.Variable([0.3], tf.float32)\n",
    "bias = tf.Variable([-0.3], tf.float32) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In [7] to In [11] shows how to compute on a graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running computations on a computational graph involves creating a session. A TF session captures the control and state of the computational graph and gives you a handle to connect to the backend computational graph. It can be created either as "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Common Pitfall #2 :: Not initializing the variables\n",
    "TensorFlow needs the variable nodes to be initialized first before making any attempts to compute anything on it. There are many ways to initialize the nodes of our computational graph. We'll stick to the simplest one which is given right below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To compute the value of a node use 'sess.run()'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(constant_node))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make something more useful by making a prediction linear in nature with the inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linear_prediction = weight * placeholder_node + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple inputs or multiple nodes can be computed simultaneously using a dictionary and a list respectively.\n",
    "Let's now evaluate the prediction given some inputs. Inputs can be fed in the graph through a dictionary as shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, array([[ 0.        ],\n",
      "       [ 0.30000001],\n",
      "       [ 0.60000002]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run([constant_node, linear_prediction], {placeholder_node:[[1],[2],[3]]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you are enough equipped with the knowledge of the basic building blocks of TF to solve the MNIST digit classification problem with this powerful library. Let's switch back to the slides again."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
