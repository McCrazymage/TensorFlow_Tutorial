{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow has many classic datasets as part of its repository which makes life of kids like us easier. MNIST is no exception. We'll import it's corresponding package. Yay!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the hyper-parameters for our network. The tricks of the trade of setting these is a topic for some other time (lecture, office-hours etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The MNIST dataset has 10 classes, representing the digits 0 through 9.\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "# The MNIST images are always 28x28 pixels.\n",
    "IMAGE_SIZE = 28\n",
    "\n",
    "# Each image is 28 X 28 in dimension. We flatten the image to get 784 features where each feature would correspond to one pixel.\n",
    "IMAGE_PIXELS = IMAGE_SIZE * IMAGE_SIZE\n",
    "\n",
    "# Batch size \n",
    "BATCH_SIZE = 100\n",
    "\n",
    "# Defining the number of units in hidden layers\n",
    "HIDDEN_LAYER_1 = 50\n",
    "HIDDEN_LAYER_2 = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Letting the tensorflow know that our inputs will contain real values only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=IMAGE_PIXELS)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our classifier. Remember those three steps. Here is it for your reference again.\n",
    "\n",
    "![The three steps](media/Steps.jpg)\n",
    "\n",
    "### Luckily for us, 'tf.contrib.learn.DNNClassifier' takes care of all these three steps by itself. Yay again!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb6c36ccef0>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './model_data'}\n"
     ]
    }
   ],
   "source": [
    "classifier = tf.contrib.learn.DNNClassifier(feature_columns=feature_columns,\n",
    "                                              hidden_units=[HIDDEN_LAYER_1, HIDDEN_LAYER_2],\n",
    "                                              n_classes=NUM_CLASSES,\n",
    "                                              model_dir=\"./model_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating functions to feed data to our 'DNNClassifier'. Remember that it accepts inputs in a particular fashion only. This is the best acceptable way of doing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the training inputs\n",
    "def get_train_inputs():\n",
    "    batch = mnist.train.next_batch(BATCH_SIZE)\n",
    "    x = tf.constant(batch[0])\n",
    "    y = tf.constant(batch[1], tf.int64)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "# Define the test inputs\n",
    "def get_test_inputs():\n",
    "    x = tf.constant(mnist.test.images)\n",
    "    y = tf.constant(mnist.test.labels, tf.int64)\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ..., 3, 2, 1. Here goes our training......... Pay attention to the value just next to the tag 'loss'. It should ideally keep on decreasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sanjay/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:642: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./model_data/model.ckpt-11000\n",
      "INFO:tensorflow:Saving checkpoints for 11001 into ./model_data/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.764125, step = 11001\n",
      "INFO:tensorflow:global_step/sec: 422.631\n",
      "INFO:tensorflow:loss = 0.00281982, step = 11101 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.183\n",
      "INFO:tensorflow:loss = 0.00160528, step = 11201 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 408.533\n",
      "INFO:tensorflow:loss = 0.00114051, step = 11301 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.616\n",
      "INFO:tensorflow:loss = 0.000889939, step = 11401 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 425.628\n",
      "INFO:tensorflow:loss = 0.000732489, step = 11501 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 430.284\n",
      "INFO:tensorflow:loss = 0.000623858, step = 11601 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 449.122\n",
      "INFO:tensorflow:loss = 0.000543942, step = 11701 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.451\n",
      "INFO:tensorflow:loss = 0.000482627, step = 11801 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 416.868\n",
      "INFO:tensorflow:loss = 0.000434098, step = 11901 (0.240 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12000 into ./model_data/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.000394167.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNClassifier(params={'head': <tensorflow.contrib.learn.python.learn.estimators.head._MultiClassHead object at 0x7fb6c36ccdd8>, 'hidden_units': [50, 20], 'feature_columns': (_RealValuedColumn(column_name='', dimension=784, default_value=None, dtype=tf.float32, normalizer=None),), 'optimizer': None, 'activation_fn': <function relu at 0x7fb6c809e8c8>, 'dropout': None, 'gradient_clip_norm': None, 'embedding_lr_multipliers': None, 'input_layer_min_slice_size': None})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model.\n",
    "classifier.fit(input_fn=get_train_inputs, steps=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating our model on test inputs. We got decent results in very quick time, didn't we? Hurrah!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sanjay/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:642: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Starting evaluation at 2017-10-24-20:51:28\n",
      "INFO:tensorflow:Restoring parameters from ./model_data/model.ckpt-12000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-10-24-20:51:29\n",
      "INFO:tensorflow:Saving dict for global step 12000: accuracy = 0.8567, global_step = 12000, loss = 0.818702\n",
      "\n",
      "Test Accuracy: 0.856700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate accuracy.\n",
    "accuracy_score = classifier.evaluate(input_fn=get_test_inputs, steps=1)[\"accuracy\"]\n",
    "\n",
    "print(\"\\nTest Accuracy: {0:f}\\n\".format(accuracy_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That was not too hard. But is this enough or do we need to know more? The answer is both yes and no, depending on what we want do you want to do with your deep learning model. Let's switch back to the slides."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
